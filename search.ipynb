{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5a4bcaea",
      "metadata": {},
      "source": [
        "# Search Notebook\n",
        "Use this notebook when you just need to load the previously indexed scene metadata + FAISS index\n",
        "and run CLIP+FAISS searches without re-extracting scene embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb56bbaa",
      "metadata": {},
      "source": [
        "## Environment\n",
        "Ensure the environment matches whatever you used to build the index (PyTorch, transformers,\n",
        "faiss-cpu, etc.). Uncomment the pip cell if you need to install packages quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a5cb87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional dependency install\n",
        "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# %pip install transformers faiss-cpu pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "25404dbc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/khushpatel/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import CLIPModel, CLIPProcessor\n",
        "import faiss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0fa398a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index root: /home/khushpatel/shortform-video-ranker/notebook_artifacts/index\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ROOT = Path('.').resolve()\n",
        "INDEX_ROOT = PROJECT_ROOT / 'notebook_artifacts' / 'index'\n",
        "\n",
        "FAISS_INDEX_PATH = Path('faiss') / 'faiss.index'\n",
        "FAISS_META_PATH = Path('faiss') / 'faiss_scene_meta.json'\n",
        "FAISS_SCENE_IDS_PATH = Path('faiss')     / 'faiss_scene_ids.json'\n",
        "VIDEO_METADATA_PATH = INDEX_ROOT / 'video_metadata.json'\n",
        "SCENE_RECORDS_PATH = INDEX_ROOT / 'scene_records.json'\n",
        "\n",
        "print('Index root:', INDEX_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1799cf0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_json(path: Path) -> Dict:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "    text = path.read_text()\n",
        "    return json.loads(text) if text else {}\n",
        "\n",
        "video_metadata = load_json(VIDEO_METADATA_PATH)\n",
        "scene_records = load_json(SCENE_RECORDS_PATH)\n",
        "faiss_scene_meta = []\n",
        "faiss_scene_ids = []\n",
        "faiss_index = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "18b7813b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded CLIP on cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
        "clip_model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
        "print('Loaded CLIP on', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9cdefff8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entries': 23820}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_faiss_artifacts(index_path=FAISS_INDEX_PATH, meta_path=FAISS_META_PATH, ids_path=FAISS_SCENE_IDS_PATH):\n",
        "    global faiss_index, faiss_scene_meta, faiss_scene_ids\n",
        "    faiss_index = faiss.read_index(str(index_path))\n",
        "    faiss_scene_meta = json.loads(Path(meta_path).read_text())\n",
        "    faiss_scene_ids = json.loads(Path(ids_path).read_text())\n",
        "    return {'entries': len(faiss_scene_ids)}\n",
        "\n",
        "faiss_stats = load_faiss_artifacts()\n",
        "faiss_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a26b971c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_with_faiss(text: str, top_scene_hits: int = 30, top_videos: int = 5) -> Dict:\n",
        "    if faiss_index is None:\n",
        "        raise ValueError('FAISS index not loaded.')\n",
        "    text_inputs = clip_processor(text=[text], return_tensors='pt', padding=True).to(device)\n",
        "    with torch.inference_mode():\n",
        "        text_features = clip_model.get_text_features(**text_inputs)\n",
        "    text_features = F.normalize(text_features, dim=-1).cpu().numpy().astype('float32')\n",
        "    k = min(top_scene_hits, faiss_index.ntotal)\n",
        "    scores, indices = faiss_index.search(text_features, k)\n",
        "\n",
        "    scene_hits = []\n",
        "    for score, idx in zip(scores[0], indices[0]):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        meta = faiss_scene_meta[idx]\n",
        "        scene_hits.append({\n",
        "            'scene_id': meta['scene_id'],\n",
        "            'video_id': meta['video_id'],\n",
        "            'score': float(score),\n",
        "            'start_frame': meta.get('start_frame'),\n",
        "            'end_frame': meta.get('end_frame'),\n",
        "        })\n",
        "\n",
        "    video_scores = {}\n",
        "    for hit in scene_hits:\n",
        "        vid = hit['video_id']\n",
        "        current = video_scores.get(vid)\n",
        "        if current is None or hit['score'] > current['score']:\n",
        "            video_scores[vid] = hit\n",
        "\n",
        "    ranked = sorted(video_scores.values(), key=lambda item: item['score'], reverse=True)[:top_videos]\n",
        "    results = []\n",
        "    for hit in ranked:\n",
        "        md = video_metadata.get(hit['video_id'], {})\n",
        "        results.append({\n",
        "            'video_id': hit['video_id'],\n",
        "            'video_uri': md.get('video_uri'),\n",
        "            'video_duration': md.get('video_duration'),\n",
        "            'score': hit['score'],\n",
        "            'scene_id': hit['scene_id'],\n",
        "            'scene_frames': (hit['start_frame'], hit['end_frame']),\n",
        "        })\n",
        "\n",
        "    return {'scene_hits': scene_hits, 'video_results': results}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "268f54f2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'video_id': '3ad0ae0c-6ae8-47e1-9753-5ca7caa89b54',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video1758.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.30197227001190186,\n",
              "  'scene_id': '83cb72d8-e80b-4673-92ba-5877c12b0db5',\n",
              "  'scene_frames': (0, 499)},\n",
              " {'video_id': '6a722f97-bc48-4548-ba7d-ac3530ed6f5a',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video5990.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.3013308644294739,\n",
              "  'scene_id': '6015a9f8-58df-4eca-bfa8-b9cb9021e682',\n",
              "  'scene_frames': (356, 360)},\n",
              " {'video_id': '958959dc-2f63-4799-a2fc-86a9a9c80290',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video1050.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.30076122283935547,\n",
              "  'scene_id': '2e4f7788-cb01-4102-82df-b42341f2920a',\n",
              "  'scene_frames': (418, 521)},\n",
              " {'video_id': '2f1b9870-0c66-45be-abd7-d3e0b5204948',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video117.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.3002801537513733,\n",
              "  'scene_id': '14e0fc3d-d225-431d-a9ff-301c424e8c19',\n",
              "  'scene_frames': (0, 17)},\n",
              " {'video_id': '0b0641ef-5884-41ca-8d4e-abe259da5461',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video5295.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.29816102981567383,\n",
              "  'scene_id': 'd4ed5d1b-836b-4c3f-9e74-a98e923e3475',\n",
              "  'scene_frames': (18, 157)},\n",
              " {'video_id': '675f78fd-b126-4d8f-b7d9-df3447aae1c2',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video1842.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.2969364523887634,\n",
              "  'scene_id': '9bcb5f44-9a96-4a96-8203-5401e146fb0c',\n",
              "  'scene_frames': (0, 86)},\n",
              " {'video_id': 'd7fd3d26-8c92-419e-aa54-d658a79c7fc6',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video1074.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.2969076931476593,\n",
              "  'scene_id': 'bb27c862-8fb5-4729-af51-584ecf747cce',\n",
              "  'scene_frames': (20, 127)},\n",
              " {'video_id': '3bee55bc-24b9-4139-81fa-8b1eb0a6b6b1',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video5220.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.29603904485702515,\n",
              "  'scene_id': '976ecee5-1ec7-4c5a-bbd6-45c0e6507345',\n",
              "  'scene_frames': (168, 219)},\n",
              " {'video_id': '853ac18d-9db5-4bde-b068-d74e7e8d6244',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video482.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.29493778944015503,\n",
              "  'scene_id': 'c58072de-d35e-4def-8d62-86a9b71d8fef',\n",
              "  'scene_frames': (118, 158)},\n",
              " {'video_id': '13f4bcd9-bb69-4b68-81d9-56dad02fd00e',\n",
              "  'video_uri': '/home/khushpatel/shortform-video-ranker/data/1/TrainValVideo/video5611.mp4',\n",
              "  'video_duration': 0.0,\n",
              "  'score': 0.29449719190597534,\n",
              "  'scene_id': 'f1292225-5df6-4044-a376-b26328a3844f',\n",
              "  'scene_frames': (0, 51)}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'a person talking to the camera'\n",
        "faiss_search_results = search_with_faiss(query, top_scene_hits=30, top_videos=10)\n",
        "faiss_search_results['video_results']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851d2a9e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
